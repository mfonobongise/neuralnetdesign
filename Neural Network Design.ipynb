{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "755c68a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65bf582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdc7b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input values\n",
    "X_num_row, X_num_col = [2,2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e2deadf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[58.81308011, 89.77137279, 89.15307295, ..., 81.51663924,\n",
       "        67.21352033, 86.30981922],\n",
       "       [10.05276968, 82.39145514, 76.93178003, ..., 39.11792936,\n",
       "        62.60018814, 20.48588988]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw = np.random.rand(X_num_row, X_num_col) * 100\n",
    "X_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "291f7a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d5c5f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output values\n",
    "Y_raw = np.concatenate(([(X_raw[0,:] + X_raw[1,:])], [(X_raw[0,:] - X_raw[1,:])], np.abs([(X_raw[0,:] - X_raw[1,:])])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26ed068b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_num_row, Y_num_col = Y_raw.shape\n",
    "Y_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28cf5910",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_ratio = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7259a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting 70% of the data to train\n",
    "Num_train_datum = int(Train_ratio * X_num_col)\n",
    "X_raw_train = X_raw[:,0:Num_train_datum]\n",
    "X_raw_test = X_raw[:,Num_train_datum:]\n",
    "Y_raw_train = Y_raw[:,0:Num_train_datum]\n",
    "Y_raw_test = Y_raw[:,Num_train_datum:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9a0e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization. zero mean and unit variance.\n",
    "class scalar:\n",
    "    def __init__(self,mean,std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "def get_scalar(row):\n",
    "    mean = np.mean(row)\n",
    "    std = np.std(row)\n",
    "    return scalar(mean,std)\n",
    "def standardize(data,scalar):\n",
    "    return (data - (scalar.mean)/scalar.std)\n",
    "def unstandardize(data,scalar):\n",
    "    return (data * scalar.std)+scalar.mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c48c2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constructing scalars from training set before constructing the neural network\n",
    "X_scalars = [get_scalar(X_raw_train[row,:]) for row in range(X_num_row)]\n",
    "X_train = np.array([standardize(X_raw_train[row,:], X_scalars[row]) for row in range(X_num_row)])\n",
    "Y_scalars = [get_scalar(Y_raw_train[row,:]) for row in range(Y_num_row)]\n",
    "Y_train = np.array([standardize(Y_raw_train[row,:], Y_scalars[row]) for row in range(Y_num_row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c25fc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array([standardize(X_raw_test[row,:], X_scalars[row]) for row in range(X_num_row)])\n",
    "Y_test = np.array([standardize(Y_raw_test[row,:], Y_scalars[row]) for row in range(Y_num_row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc39b140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47.98095742822924, 49.74505071599517]\n",
      "[28.89937670411455, 28.98437383047892]\n",
      "[98.72675138335849, -1.7778078139387639, 32.412321337547404]\n",
      "[40.543788044538964, 41.31267422307638, 23.774224792986935]\n"
     ]
    }
   ],
   "source": [
    "print([X_train[row,:].mean() for row in range(X_num_row)])\n",
    "print([X_train[row,:].std() for row in range(X_num_row)])\n",
    "print([Y_train[row,:].mean() for row in range(Y_num_row)])\n",
    "print([Y_train[row,:].std() for row in range(Y_num_row)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "558d86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class layer:\n",
    "    def __init__(self, layer_index, is_output, input_dim, output_dim, activation):\n",
    "        self.layer_index = layer_index\n",
    "        self.is_output = is_output\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.activation = activation\n",
    "        \n",
    "        if layer_index != 0:\n",
    "            self.w = np.random.randn(output_dim, input_dim) * np.sqrt(2/input_dim)\n",
    "            self.b = np.random.randn(output_dim, 1)*np.sqrt(2/input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78f0cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_dim = [X_num_row,4,4,Y_num_row]\n",
    "Neural_net = []\n",
    "\n",
    "for layer_index in range(len(layers_dim)):\n",
    "    if layer_index == 0:\n",
    "        Neural_net.append(layer(layer_index, False, 0, layers_dim[layer_index], 'irrelevant'))\n",
    "    elif layer_index + 1 == len(layers_dim):\n",
    "        Neural_net.append(layer(layer_index, True, layers_dim[layer_index - 1], layers_dim[layer_index], activation='linear'))\n",
    "    else:\n",
    "        Neural_net.append(layer(layer_index, False, layers_dim[layer_index - 1], layers_dim[layer_index], activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91ae0f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number of hyperparameters: 47\n",
      "Actual number of hyperparameters: 47\n",
      "Number of data: 2000\n"
     ]
    }
   ],
   "source": [
    "pred_n_param = sum([(layers_dim[layer_index]+1)*layers_dim[layer_index+1] for layer_index in range(len(layers_dim)-1)])\n",
    "act_n_param = sum([Neural_net[layer_index].w.size + Neural_net[layer_index].b.size for layer_index in range(1,len(layers_dim))])\n",
    "print(f'Predicted number of hyperparameters: {pred_n_param}')\n",
    "print(f'Actual number of hyperparameters: {act_n_param}')\n",
    "print(f'Number of data: {X_num_col}')\n",
    "\n",
    "if act_n_param >= X_num_col:\n",
    "    raise Exception(\"It will overfit.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "435619d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(input_, act_function):\n",
    "    if act_function == 'relu':\n",
    "        return np.maximum(input_, np.zeros(input_.shape))\n",
    "    elif act_function == 'linear':\n",
    "        return input_\n",
    "    else:\n",
    "        raise Exception('Activation function is not defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b834e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(input_vec, layers_dim = layers_dim, Neural_net = Neural_net):\n",
    "    Neural_net[0].a = input_vec\n",
    "    for layer_index in range(1,len(layers_dim)):\n",
    "        Neural_net[layer_index].z = np.add(np.dot(Neural_net[layer_index].w, Neural_net[layer_index-1].a), Neural_net[layer_index].b)\n",
    "        Neural_net[layer_index].a = activation(Neural_net[layer_index].z, Neural_net[layer_index].activation)\n",
    "    return Neural_net[layer_index].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6330d201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_prop(X_train).shape == Y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16c09853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(Y,Y_hat, metric = 'mse'):\n",
    "    if metric == 'mse':\n",
    "        individual_loss = 0.5 * (Y_hat - Y)**2\n",
    "        return np.mean([np.linalg.norm(individual_loss[:,col],2) for col in range (individual_loss.shape[1])])\n",
    "    else:\n",
    "        raise Exception('Loss metric is not defined')\n",
    "def get_dz_from_loss(Y,Y_hat,metric):\n",
    "    if metric == 'mse':\n",
    "        return Y_hat - Y\n",
    "    else:\n",
    "        raise Exception('Loss metric is not defined')\n",
    "def get_deactivation(a, act_function):\n",
    "    if act_function == 'relu':\n",
    "        return np.maximum(np.sign(a), np.zeros(a.shape))\n",
    "    elif act_function == 'linear':\n",
    "        return np.ones(a.shape)\n",
    "    else:\n",
    "        raise Exception('Activation function is not defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50630a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(Y, Y_hat,metric = 'mse', layers_dim = layers_dim, Neural_net = Neural_net, Num_train_datum = Num_train_datum):\n",
    "    for layer_index in range(len(layers_dim)-1,0,-1):\n",
    "        if layer_index+1 == len(layers_dim):\n",
    "            dz = get_dz_from_loss(Y, Y_hat, metric)\n",
    "        else:\n",
    "            dz = np.multiply(np.dot(Neural_net[layer_index + 1].w.t, dz), get_deactivation(Neural_net[layer_index].a, Neural_net[layer_index].activation))\n",
    "        \n",
    "        dw = np.dot(dz, Neural_net[layer_index-1].a.t) / Num_train_datum\n",
    "        db = np.sum(dz, axis = 1, keepdims = True) / Num_train_datum\n",
    "        \n",
    "        Neural_net[layer_index].dw = dw\n",
    "        Neural_net[layer_index].db = db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66e050",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f99d71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5614.781215435073\n"
     ]
    }
   ],
   "source": [
    "print(get_loss(Y_test, forward_prop(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ac0b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_raw_any):\n",
    "    X_any = np.array([standardize(X_raw_any[row,:], X_scalars[row]) for row in range(X_num_row)])\n",
    "    Y_hat = forward_prop(X_any)\n",
    "    Y_hat_any = np.array([unstandardize(Y_hat[row,:], Y_scalars[row]) for row in range(Y_num_row)])\n",
    "    return Y_hat_any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "656b35fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 163.22428687,  302.42540662],\n",
       "       [  69.38298228,  174.47180656],\n",
       "       [  32.65643104, -129.27313089]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(np.array([[40,60],[60,40],[5,9],[766,354]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013bebad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
